{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Shirt Images - Data Transformations\n",
    "\n",
    "\n",
    "This notebook reads all the received datasets from Threadless and select(copies) only those that are present in the 'AllData.xlsx' that has the images (~10k) to be analyzed. Once the necessary images are selected and moved to a different folder, some preprocessing steps are performed like - <br> <br>\n",
    "i) Image Resizing (256 * 256) <br>\n",
    "ii) Padding the images such as to maintain the aspect ratio while having the final image size as 256* 256 <br>\n",
    "    * Padding with black color might not help a lot with classification, so the images are padded with majority R,G and B colors\n",
    "    * There are cases where the majority R, G and B color are not the background image, but the contents of the images. So, only outer pixels will be looked for while selecting the major background color\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvra\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the transformed version of 'AllData.xlsx' file\n",
    "#Major_Background_labels has been transformed to have the Background tagging for each image\n",
    "\n",
    "one_hot_output = pd.read_csv('Major_Background_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving all the images from different folders to one consolidated folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes have been commented to prevent them from executing again (considering the execution time and also because they are one time process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst = \"C:\\\\Users\\\\arvra\\\\Documents\\\\UVa files\\\\Research Assistantship\\\\Final data\\\\\"\n",
    "# for subdir, dirs, files in os.walk(\"C:\\\\Users\\\\arvra\\\\Documents\\\\data\"):\n",
    "#     #print(subdir)\n",
    "#     if(len(os.listdir(subdir)) < 100 ):\n",
    "#         continue\n",
    "#     for each in os.listdir(subdir):\n",
    "#         if(each.split(\".\")[0] in one_hot_output.Index.values):\n",
    "#             shutil.copy(subdir+\"\\\\\"+each, dst+each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# all_files = [each.split(\".\")[0] for each in os.listdir(dst)]\n",
    "# all_files_counter = Counter(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: Moving only those images which are present in AllData.xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Destination location ###\n",
    "# ### final_data = \"C:\\\\Users\\\\arvra\\\\Documents\\\\UVa files\\\\Research Assistantship\\\\Final data Analysis\\\\\"\n",
    "\n",
    "# for each in os.listdir(dst):\n",
    "#     file_name = each.split(\".\")[0]\n",
    "#     if(all_files_counter[file_name] > 1):\n",
    "        \n",
    "#         continue\n",
    "        \n",
    "#     else:\n",
    "#         shutil.copy(dst+each, final_data+each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.stat(dst+each).st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each_file in all_files_counter.keys():\n",
    "#     if all_files_counter[each_file] > 1:\n",
    "        \n",
    "#         similar_images = [file for file in os.listdir(dst) if each_file == file.split(\".\")[0]]\n",
    "        \n",
    "#         selected_image = []\n",
    "#         size = 10000000000\n",
    "#         for each in similar_images:\n",
    "#             if( os.stat(dst+each).st_size < size):\n",
    "#                 size = os.stat(dst+each).st_size\n",
    "#                 selected_image = each\n",
    "#         shutil.copy(dst+each, final_data+selected_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the images to 256 x 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Setting the directory to move the transformed images (while splitting them to train and validation dataset)\n",
    "image_data_out_train = \"C:\\\\Users\\\\arvra\\\\Documents\\\\UVa files\\\\Research Assistantship\\\\Final data Folders\\\\train\\\\\"\n",
    "image_data_out_val = \"C:\\\\Users\\\\arvra\\\\Documents\\\\UVa files\\\\Research Assistantship\\\\Final data Folders\\\\val\\\\\"\n",
    "\n",
    "#### Input Raw that will be used for our analysis ####\n",
    "image_data = \"C:\\\\Users\\\\arvra\\\\Documents\\\\UVa files\\\\Research Assistantship\\\\Final data Analysis\"\n",
    "images = os.listdir(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting the image numbers from the directory\n",
    "image_numbers = [each.replace(\".jpg\",\"\").replace(\".png\",\"\").replace(\".gif\",\"\") for each in images]\n",
    "available_images = [each for each in image_numbers if each in one_hot_output.Image_index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove unnecessary images\n",
    "## Removing '176194' since we have a file, but we do not have an image for this file\n",
    "remove_imgs = ['176194']\n",
    "\n",
    "image_numbers = [(each.split(\".\")[0],each) for each in images]\n",
    "available_files = [(avail,files) for avail,files in image_numbers \\\n",
    "                   if avail in list(one_hot_output.Image_index) and avail not in remove_imgs]\n",
    "\n",
    "## Available images\n",
    "available_images = [img for img,files in available_files]\n",
    "\n",
    "file_names = [files for img,files in available_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading necessary libraries\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from PIL import ImageFile\n",
    "import random\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Splitting the data to train and validation\n",
    "train_files = random.sample(available_files, int(len(available_files) * 0.7))\n",
    "val_files = [each for each in available_files if each not in train_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING TRAINING FOLDER\n",
      "CREATING VALIDATION FOLDER\n"
     ]
    }
   ],
   "source": [
    "### Final aspect ratio\n",
    "desired_size = 512\n",
    "\n",
    "images_dict = {}\n",
    "images_dict_new = {}\n",
    "image_array = []\n",
    "image_with_aspect = []\n",
    "sizes = []\n",
    "\n",
    "print(\"CREATING TRAINING FOLDER\")\n",
    "\n",
    "\n",
    "############################## CREATING FOLDER FOR TRAINING IMAGES ##########################################\n",
    "for image,file in train_files:\n",
    "    #images_dict[each] = np.array(Image.open())\n",
    "    #image = scipy.ndimage.imread(image_data+'\\\\'+file, mode=\"RGB\")\n",
    "\n",
    "    ##Reading the input file\n",
    "    im = Image.open(image_data+'\\\\'+file)\n",
    "    old_size = im.size  # old_size[0] is in (width, height) format\n",
    "    \n",
    "    ##Getting the ratio and setting the new size\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    # use thumbnail() or resize() method to resize the input image\n",
    "    # thumbnail is a in-place operation\n",
    "    # im.thumbnail(new_size, Image.ANTIALIAS)\n",
    "    im = im.resize(new_size, Image.ADAPTIVE)\n",
    "    \n",
    "    ############### CREATING A NEW IMAGE WITH COLOR PADDING ###########################\n",
    "    im2 = im.convert('RGB')\n",
    "    histogram = im2.histogram()\n",
    "    # Take only the Red counts\n",
    "    l1 = histogram[0:256]\n",
    "    # Take only the Blue counts\n",
    "    l2 = histogram[256:512]\n",
    "    # Take only the Green counts\n",
    "    l3 = histogram[512:768]\n",
    "\n",
    "    r,g,b = np.argmax(l1),np.argmax(l2),np.argmax(l3)\n",
    "    #####################################################################################\n",
    "    \n",
    "    # create a new image and paste the resized on it\n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size),(r,g,b))\n",
    "    new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                        (desired_size-new_size[1])//2))\n",
    "    image_with_aspect.append(new_im)\n",
    "    subfolder = one_hot_output[one_hot_output.Image_index == image]['Major_backgroup'].values\n",
    "    \n",
    "    directory = image_data_out_train+str(subfolder[0])\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    new_im.save(image_data_out_train+str(subfolder[0])+\"\\\\\"+file)\n",
    "    \n",
    "    \n",
    "############################## CREATING FOLDER FOR VALIDATION IMAGES ########################################## \n",
    "\n",
    "print(\"CREATING VALIDATION FOLDER\")\n",
    "\n",
    "for image,file in val_files:\n",
    "    #images_dict[each] = np.array(Image.open())\n",
    "    #image = scipy.ndimage.imread(image_data+'\\\\'+file, mode=\"RGB\")\n",
    "\n",
    "    ##Reading the input file\n",
    "    im = Image.open(image_data+'\\\\'+file)\n",
    "    old_size = im.size  # old_size[0] is in (width, height) format\n",
    "    \n",
    "    ##Getting the ratio and setting the new size\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "\n",
    "    # use thumbnail() or resize() method to resize the input image\n",
    "    # thumbnail is a in-place operation\n",
    "    # im.thumbnail(new_size, Image.ANTIALIAS)\n",
    "    im = im.resize(new_size, Image.ADAPTIVE)\n",
    "    \n",
    "    \n",
    "    ############### CREATING A NEW IMAGE WITH COLOR PADDING ###########################\n",
    "    im2 = im.convert('RGB')\n",
    "    histogram = im2.histogram()\n",
    "    # Take only the Red counts\n",
    "    l1 = histogram[0:256]\n",
    "    # Take only the Blue counts\n",
    "    l2 = histogram[256:512]\n",
    "    # Take only the Green counts\n",
    "    l3 = histogram[512:768]\n",
    "\n",
    "    r,g,b = np.argmax(l1),np.argmax(l2),np.argmax(l3)\n",
    "    #####################################################################################\n",
    "    \n",
    "    # create a new image and paste the resized on it\n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size),(r,g,b))\n",
    "    new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                        (desired_size-new_size[1])//2))\n",
    "    image_with_aspect.append(new_im)\n",
    "    subfolder = one_hot_output[one_hot_output.Image_index == image]['Major_backgroup'].values\n",
    "    \n",
    "    directory = image_data_out_val+str(subfolder[0])\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    new_im.save(image_data_out_val+str(subfolder[0])+\"\\\\\"+file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
