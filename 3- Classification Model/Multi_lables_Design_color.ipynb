{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/embsysa/fastai/pytorch_classifiers-master/data/\"\n",
    "sz = 224\n",
    "arch = resnet50\n",
    "bs = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = \"/home/embsysa/fastai/pytorch_classifiers-master/data\"\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all_mask.zip\t\t\t\t     Graphics_Multi_lables.csv.csv\r\n",
      " Background_color_allmultilabel.csv\t     labels.zip\r\n",
      " Background_color_allmultilabel.csv.csv      Major_Background_labels.csv\r\n",
      " Background_color_all_Multi_lables.csv\t     Major_Graphics_labels.csv\r\n",
      " Background_color_all_Multi_lables.csv.csv   Major_Graphics_labels.csv.csv\r\n",
      " Backup\t\t\t\t\t     Major_Graphics_labels_final.csv\r\n",
      "'change file type.ipynb'\t\t     models\r\n",
      " cifar-10-batches-py\t\t\t     old_Major_Background_labels.csv\r\n",
      " cifar-10-python.tar.gz\t\t\t     test\r\n",
      " Design_color_all_Multi_lables.csv\t     Theme_labels.csv\r\n",
      " Design_color_all_Multi_lables.csv.csv\t     Theme_labels.csv.csv\r\n",
      " Design_contrast_color_labels.csv\t     tmp\r\n",
      " Emotional_strength_labels.csv\t\t     train\r\n",
      " Emotional_strength_labels.csv.csv\t     train_py\r\n",
      " Emotion_labels.csv\t\t\t     train_py_contrast\r\n",
      " Emotion_labels.csv.csv\t\t\t     train_py_emotiona_srengh\r\n",
      "'Final data Folders'\t\t\t     train_py_major_graphics\r\n",
      "'Final data Folders.zip'\t\t     train_py_theme\r\n",
      " Graphics_Multi_lables.csv\t\t     train_with_mask\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}\n",
    "\n",
    "label_csv_name = 'Design_color_all_Multi_lables.csv'\n",
    "label_df = pd.read_csv(label_csv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [each.split(\".jpg\")[0] for each in os.listdir(data_path+\"/train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_index</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>4 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>1 3 4 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>698</td>\n",
       "      <td>1 2 4 5 8 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769</td>\n",
       "      <td>1 2 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>786</td>\n",
       "      <td>1 6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_index     variable\n",
       "0          28          4 6\n",
       "1          40      1 3 4 8\n",
       "2         698  1 2 4 5 8 9\n",
       "3         769        1 2 3\n",
       "4         786          1 6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_df[label_df.Image_index.isin(images)]\n",
    "label_df.to_csv(label_csv_name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Design_color_all_Multi_lables.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_csv_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv = f'{PATH}'+label_csv_name+'.csv'\n",
    "n = len(label_df)# header is not counted (-1)\n",
    "val_idxs = get_cv_idxs(n) # random 20% data for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9955, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.columns = label_df.columns.str.replace(\"-\",\"_\")\n",
    "label_df.head()\n",
    "#label_df.columns = ['id', 'color']\n",
    "\n",
    "label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9954"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_df.pivot_table(index=\"color\", aggfunc=len).sort_values('id', ascending=False)\n",
    "import numpy as np\n",
    "np.max(val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/embsysa/fastai/pytorch_classifiers-master/data/train/40.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1.2)\n",
    "data = ImageClassifierData.from_csv(PATH, 'train', label_csv, test_name='test', # we need to specify where the test set is if you want to submit to Kaggle competitions\n",
    "                                   val_idxs=val_idxs, suffix='.jpg', tfms=tfms, bs=bs)\n",
    "\n",
    "fn = PATH + data.trn_ds.fnames[0];\n",
    "print(fn)\n",
    "\n",
    "data.trn_ds.fnames[0]\n",
    "\n",
    "img = PIL.Image.open(fn); img\n",
    "\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1991"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_d = {k: PIL.Image.open(PATH + k).size for k in data.trn_ds.fnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz, col_sz = list(zip(*size_d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz = np.array(row_sz); col_sz = np.array(col_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bs): # sz: image size, bs: batch size\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.2)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'train', label_csv, test_name='test',\n",
    "                                       val_idxs=val_idxs, suffix='.jpg', tfms=tfms,bs = bs)\n",
    "    \n",
    "    # http://forums.fast.ai/t/how-to-train-on-the-full-dataset-using-imageclassifierdata-from-csv/7761/13\n",
    "    # http://forums.fast.ai/t/how-to-train-on-the-full-dataset-using-imageclassifierdata-from-csv/7761/37\n",
    "    return data if sz > 300 else data.resize(256, 'tmp') # Reading the jpgs and resizing is slow for big images, so resizing them all to 340 first saves time\n",
    "\n",
    "#Source:   \n",
    "#    def resize(self, targ, new_path):\n",
    "#        new_ds = []\n",
    "#        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n",
    "#        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n",
    "#        else: dls += [None,None]\n",
    "#        t = tqdm_notebook(dls)\n",
    "#        for dl in t: new_ds.append(self.resized(dl, targ, new_path))\n",
    "#        t.close()\n",
    "#        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n",
    "#File:      ~/fastai/courses/dl1/fastai/dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.dataset import *\n",
    "from sklearn.metrics import fbeta_score\n",
    "import warnings\n",
    "\n",
    "def f2(preds, targs, start=0.17, end=0.24, step=0.01):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        return max([fbeta_score(targs, (preds>th), 2, average='samples')\n",
    "                    for th in np.arange(start,end,step)])\n",
    "\n",
    "metrics=[f2]\n",
    "f_model = resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9febc1697f447da1acd55b64176c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/embsysa/.torch/models/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [00:03<00:00, 26801743.18it/s]\n"
     ]
    }
   ],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=False, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "# set requires_grads to be True for all layers, so they can be updated\n",
    "\n",
    "learning_rate = [0.01, 0.01, 0.1]\n",
    "# learning rate is set so that deepest third of layers have a rate of 0.001, # middle layers have a rate of 0.01, and final layers 0.1.\n",
    "\n",
    "\n",
    "learn.precompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3ab24395ae4265950ca74b40b9051b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f2                          \n",
      "    0      0.153795   0.148198   0.746664  \n",
      "    1      0.153146   0.147729   0.748073                    \n",
      "    2      0.151768   0.147507   0.747969                    \n",
      "    3      0.150855   0.14698    0.749022                    \n",
      "    4      0.153408   0.146973   0.748813                    \n",
      "    5      0.150437   0.146483   0.749338                    \n",
      "    6      0.149901   0.146675   0.748847                    \n",
      "    7      0.149115   0.146539   0.749169                    \n",
      "    8      0.147235   0.145833   0.749854                    \n",
      "    9      0.149241   0.14627    0.749073                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14626997643412806, 0.7490732790863766]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Multi_lables_Design_color')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA() # (5, 2044, 120), (2044,)\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "#accuracy_np(probs, y), metrics.log_loss(y, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2(probs,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.precompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 30, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Multi_lables_Design_color3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Multi_lables_Design_color3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting training on small images for a few epochs, then switching to bigger images, and continuing training is an amazingly effective way to avoid overfitting.\n",
    "\n",
    "# http://forums.fast.ai/t/planet-classification-challenge/7824/96\n",
    "# set_data doesn’t change the model at all. It just gives it new data to train with.\n",
    "learn.set_data(get_data(299, bs)) \n",
    "learn.freeze()\n",
    "\n",
    "#Source:   \n",
    "#    def set_data(self, data, precompute=False):\n",
    "#        super().set_data(data)\n",
    "#        if precompute:\n",
    "#            self.unfreeze()\n",
    "#            self.save_fc1()\n",
    "#            self.freeze()\n",
    "#            self.precompute = True\n",
    "#        else:\n",
    "#            self.freeze()\n",
    "#File:      ~/fastai/courses/dl1/fastai/conv_learner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 50, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss is much lower than training loss. This is a sign of underfitting. Cycle_len=1 may be too short. Let's set cycle_mult=2 to find better parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "# set requires_grads to be True for all layers, so they can be updated\n",
    "\n",
    "learning_rate = [1e-5, 1e-5, 1e-4]\n",
    "# learning rate is set so that deepest third of layers have a rate of 0.001, # middle layers have a rate of 0.01, and final layers 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you are under fitting, it means cycle_len=1 is too short (learning rate is getting reset before it had the chance to zoom in properly).\n",
    "learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2) # 1+2+4 = 7 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loss and validation loss are getting closer and smaller. We are on right track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA() # (5, 2044, 120), (2044,)\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "#accuracy_np(probs, y), metrics.log_loss(y, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.iloc[3145,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 23\n",
    "\n",
    "print(val_idxs[num])\n",
    "print(np.argmax(y[num]))\n",
    "y[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(probs[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.val_ds.y), data.val_ds.y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 13\n",
    "print(data.val_ds.y[num])\n",
    "print(np.argmax(probs[num]))\n",
    "\n",
    "print(probs[num])\n",
    "data.val_ds.fnames[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(probs,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame([data.val_ds.y,np.argmax(probs,axis = 1),\n",
    "                            [each[1] for each in np.argsort(-probs,axis = 1)],\n",
    "                            data.val_ds.fnames]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.loc[:,'acc1'] = predictions[0] == predictions[1]\n",
    "predictions.loc[:,'acc2'] = predictions[0] == predictions[2]\n",
    "((predictions.acc1) | (predictions.acc2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.acc1.sum()/1883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Multi_lables_Design_color1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Multi_lables_Design_color2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 1, cycle_len=2) # 1+1 = 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Multi_lables_Design_color2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(probs, y), metrics.log_loss(y, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is so similar to ImageNet dataset. Training convolution layers doesn't help much. We are not going to unfreeze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission\n",
    "\n",
    "https://youtu.be/9C06ZPF8Uuc?t=1905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds.fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA(is_test=True) # use test dataset rather than validation dataset\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "#accuracy_np(probs, y), metrcs.log_loss(y, probs) # This does not make sense since test dataset has no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape # (n_images, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(probs)\n",
    "df.columns = data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'id', [o[5:-4] for o in data.test_ds.fnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM = f'{PATH}/subm/'\n",
    "os.makedirs(SUBM, exist_ok=True)\n",
    "df.to_csv(f'{SUBM}subm.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(f'{SUBM}subm.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = data.val_ds.fnames[0]\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(PATH + fn).resize((150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1.\n",
    "trn_tfms, val_tfms = tfms_from_model(arch, sz)\n",
    "ds = FilesIndexArrayDataset([fn], np.array([0]), val_tfms, PATH)\n",
    "dl = DataLoader(ds)\n",
    "preds = learn.predict_dl(dl)\n",
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.classes[np.argmax(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2.\n",
    "trn_tfms, val_tfms = tfms_from_model(arch, sz)\n",
    "im = val_tfms(open_image(PATH + fn)) # open_image() returns numpy.ndarray\n",
    "preds = learn.predict_array(im[None])\n",
    "np.argmax(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
