{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs breeds\n",
    "\n",
    "https://youtu.be/JNxcznsrRb8?t=1h31m8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/embsysa/fastai/pytorch_classifiers-master/data/\"\n",
    "sz = 224\n",
    "arch = resnet34\n",
    "bs = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = \"/home/embsysa/fastai/pytorch_classifiers-master/data\"\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all_mask.zip\t\t\t\t  Major_Background_labels.csv\r\n",
      " Background_color_allmultilabel.csv\t  Major_Graphics_labels.csv\r\n",
      " Background_color_allmultilabel.csv.csv   Major_Graphics_labels.csv.csv\r\n",
      " Backup\t\t\t\t\t  Major_Graphics_labels_final.csv\r\n",
      "'change file type.ipynb'\t\t  old_Major_Background_labels.csv\r\n",
      " Emotion_labels.csv\t\t\t  test\r\n",
      " Emotion_labels.csv.csv\t\t\t  tmp\r\n",
      "'Final data Folders'\t\t\t  train\r\n",
      "'Final data Folders.zip'\t\t  train_with_mask\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}\n",
    "\n",
    "label_csv_name = 'Emotion_labels.csv'\n",
    "label_df = pd.read_csv(label_csv_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [each.split(\".jpg\")[0] for each in os.listdir(data_path+\"/train\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_index</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>698</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>786</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_index Emotion\n",
       "0          28       P\n",
       "1          40       N\n",
       "2         698       P\n",
       "3         769       P\n",
       "4         786       N"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = label_df[label_df.Image_index.isin(images)]\n",
    "label_df.to_csv(label_csv_name+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emotion_labels.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_csv_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv = f'{PATH}'+label_csv_name+'.csv'\n",
    "n = len(label_df)# header is not counted (-1)\n",
    "val_idxs = get_cv_idxs(n) # random 20% data for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9946, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.columns = label_df.columns.str.replace(\"-\",\"_\")\n",
    "label_df.head()\n",
    "#label_df.columns = ['id', 'color']\n",
    "\n",
    "label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9944"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_df.pivot_table(index=\"color\", aggfunc=len).sort_values('id', ascending=False)\n",
    "import numpy as np\n",
    "np.max(val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/embsysa/fastai/pytorch_classifiers-master/data/train/40.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1.2)\n",
    "data = ImageClassifierData.from_csv(PATH, 'train', label_csv, test_name='test', # we need to specify where the test set is if you want to submit to Kaggle competitions\n",
    "                                   val_idxs=val_idxs, suffix='.jpg', tfms=tfms, bs=bs)\n",
    "\n",
    "fn = PATH + data.trn_ds.fnames[0];\n",
    "print(fn)\n",
    "\n",
    "data.trn_ds.fnames[0]\n",
    "\n",
    "img = PIL.Image.open(fn); img\n",
    "\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_d = {k: PIL.Image.open(PATH + k).size for k in data.trn_ds.fnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz, col_sz = list(zip(*size_d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz = np.array(row_sz); col_sz = np.array(col_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bs): # sz: image size, bs: batch size\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.2)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'train', label_csv, test_name='test',\n",
    "                                       val_idxs=val_idxs, suffix='.jpg', tfms=tfms,bs = bs)\n",
    "    \n",
    "    # http://forums.fast.ai/t/how-to-train-on-the-full-dataset-using-imageclassifierdata-from-csv/7761/13\n",
    "    # http://forums.fast.ai/t/how-to-train-on-the-full-dataset-using-imageclassifierdata-from-csv/7761/37\n",
    "    return data if sz > 300 else data.resize(256, 'tmp') # Reading the jpgs and resizing is slow for big images, so resizing them all to 340 first saves time\n",
    "\n",
    "#Source:   \n",
    "#    def resize(self, targ, new_path):\n",
    "#        new_ds = []\n",
    "#        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n",
    "#        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n",
    "#        else: dls += [None,None]\n",
    "#        t = tqdm_notebook(dls)\n",
    "#        for dl in t: new_ds.append(self.resized(dl, targ, new_path))\n",
    "#        t.close()\n",
    "#        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n",
    "#File:      ~/fastai/courses/dl1/fastai/dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bd046d5443464d9cdbaf7cdddcc26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "# set requires_grads to be True for all layers, so they can be updated\n",
    "\n",
    "learning_rate = [0.01, 0.01, 0.1]\n",
    "# learning rate is set so that deepest third of layers have a rate of 0.001, # middle layers have a rate of 0.01, and final layers 0.1.\n",
    "\n",
    "\n",
    "learn.precompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8da1a8040a4ca0af40eddb0d99ac5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.70561    0.670311   0.589744  \n",
      "    1      0.70259    0.669082   0.588738                    \n",
      "    2      0.710278   0.674025   0.58371                     \n",
      "    3      0.720694   0.6691     0.589744                    \n",
      "    4      0.706983   0.672902   0.58371                     \n",
      "    5      0.716244   0.674016   0.582202                    \n",
      "    6      0.712162   0.670489   0.584213                    \n",
      "    7      0.704311   0.669369   0.589241                    \n",
      "    8      0.708938   0.673322   0.582705                    \n",
      "    9      0.71751    0.670292   0.583208                    \n",
      "    10     0.705293   0.670864   0.585219                    \n",
      "    11     0.712002   0.678431   0.576672                    \n",
      "    12     0.698858   0.672541   0.581197                    \n",
      "    13     0.709668   0.67524    0.585219                    \n",
      "    14     0.70078    0.67197    0.583208                    \n",
      "    15     0.711332   0.673263   0.582705                    \n",
      "    16     0.716403   0.671268   0.586727                    \n",
      "    17     0.704613   0.672155   0.580191                    \n",
      "    18     0.706997   0.670972   0.587733                    \n",
      "    19     0.714859   0.672365   0.590246                    \n",
      "    20     0.712194   0.669671   0.590246                    \n",
      "    21     0.699703   0.671457   0.580191                    \n",
      "    22     0.700199   0.673723   0.58723                     \n",
      "    23     0.710263   0.669344   0.591252                    \n",
      "    24     0.710273   0.671086   0.58723                     \n",
      "    25     0.70051    0.674874   0.573152                    \n",
      "    26     0.713011   0.675776   0.576169                    \n",
      "    27     0.697634   0.677854   0.578683                    \n",
      "    28     0.714313   0.670786   0.586727                    \n",
      "    29     0.699928   0.672424   0.58371                     \n",
      "    30     0.707494   0.67355    0.582705                    \n",
      "    31     0.703639   0.670349   0.581197                    \n",
      "    32     0.711703   0.674167   0.583208                    \n",
      "    33     0.696927   0.671934   0.582705                    \n",
      "    34     0.701547   0.673527   0.583208                    \n",
      "    35     0.705651   0.674225   0.582705                    \n",
      "    36     0.692437   0.674056   0.588235                    \n",
      "    37     0.704134   0.67005    0.587733                    \n",
      "    38     0.705056   0.67119    0.58371                     \n",
      "    39     0.702322   0.675675   0.582202                    \n",
      "    40     0.703823   0.669638   0.593766                    \n",
      "    41     0.698084   0.671838   0.584716                    \n",
      "    42     0.708889   0.676926   0.581197                    \n",
      "    43     0.705297   0.674308   0.57818                     \n",
      "    44     0.70321    0.675725   0.580191                    \n",
      "    45     0.704844   0.676079   0.576169                    \n",
      "    46     0.717378   0.671089   0.588738                    \n",
      "    47     0.707581   0.670868   0.590246                    \n",
      "    48     0.710154   0.67184    0.584716                    \n",
      "    49     0.703827   0.671039   0.58723                     \n",
      "    50     0.700547   0.670651   0.584716                    \n",
      "    51     0.713472   0.67855    0.579186                    \n",
      "    52     0.70138    0.679737   0.585721                    \n",
      "    53     0.698623   0.676685   0.581699                    \n",
      "    54     0.705136   0.672108   0.585721                    \n",
      "    55     0.695343   0.669886   0.588235                    \n",
      "    56     0.693996   0.672183   0.579688                    \n",
      "    57     0.707594   0.670333   0.587733                    \n",
      "    58     0.705306   0.670411   0.589241                    \n",
      " 72%|███████▏  | 240/332 [00:40<00:13,  6.63it/s, loss=0.696]"
     ]
    }
   ],
   "source": [
    "learn.fit(1e-5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model-emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/embsysa/fastai/pytorch_classifiers-master/data/tmp/256/models/model-emoation.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2f5380e8f821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model-emoation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# list \"detatches\" the iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/embsysa/fastai/pytorch_classifiers-master/data/tmp/256/models/model-emoation.h5'"
     ]
    }
   ],
   "source": [
    "learn.load('model-emoation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86820ee924d7410184b56c5743622e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.713014   0.671208   0.588235  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6712083112600162, 0.5882353123676364]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-4,1,best_save_name = 'model1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc47d7970444b379e97944470c4fe26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [00:11<00:00, 29.65it/s]\n",
      "100%|██████████| 83/83 [00:02<00:00, 28.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 25.09it/s]\n"
     ]
    }
   ],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ffddb6caa54e299e56700c4faa331b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.933143   0.737388   0.533937  \n",
      "    1      0.871906   0.735737   0.564605                    \n",
      "    2      0.811323   0.745391   0.512821                    \n",
      "    3      0.765969   0.694822   0.576672                    \n",
      "    4      0.751269   0.696843   0.570639                    \n",
      "    5      0.753415   0.686339   0.59628                     \n",
      "    6      0.726065   0.699692   0.54902                     \n",
      "    7      0.739758   0.684116   0.576672                    \n",
      "    8      0.728431   0.683846   0.584716                    \n",
      "    9      0.716244   0.7011     0.543992                    \n",
      "    10     0.706878   0.678616   0.576169                    \n",
      "    11     0.676469   0.6708     0.59628                     \n",
      "    12     0.676268   0.691095   0.562594                    \n",
      "    13     0.680057   0.68027    0.581197                    \n",
      "    14     0.67905    0.668335   0.590246                    \n",
      "    15     0.67916    0.677417   0.568627                    \n",
      "    16     0.673968   0.676784   0.576169                    \n",
      "    17     0.6756     0.684116   0.57265                     \n",
      "    18     0.66526    0.67978    0.571644                    \n",
      "    19     0.658483   0.667482   0.595777                    \n",
      "    20     0.661048   0.68148    0.565108                    \n",
      "    21     0.661322   0.676996   0.576672                    \n",
      "    22     0.661764   0.672236   0.598291                    \n",
      "    23     0.650218   0.677147   0.580694                    \n",
      "    24     0.667578   0.681787   0.566616                    \n",
      "    25     0.6622     0.672612   0.574158                    \n",
      "    26     0.656339   0.68661    0.553545                    \n",
      "    27     0.652178   0.677338   0.576672                    \n",
      "    28     0.650698   0.673272   0.58371                     \n",
      "    29     0.649069   0.673521   0.59628                     \n",
      "    30     0.639532   0.677777   0.575666                    \n",
      "    31     0.645781   0.687975   0.565108                    \n",
      "    32     0.648594   0.685729   0.561589                    \n",
      "    33     0.635216   0.682514   0.571141                    \n",
      "    34     0.633938   0.675998   0.57818                     \n",
      "    35     0.64834    0.673001   0.580694                    \n",
      "    36     0.631566   0.677786   0.571644                    \n",
      "    37     0.622765   0.678418   0.580191                    \n",
      "    38     0.633774   0.675957   0.581699                    \n",
      "    39     0.628302   0.67998    0.577174                    \n",
      "    40     0.640125   0.691587   0.559075                    \n",
      "    41     0.638364   0.684218   0.576672                    \n",
      "    42     0.622659   0.697015   0.546506                    \n",
      "    43     0.630096   0.693619   0.5636                      \n",
      "    44     0.63718    0.684105   0.577677                    \n",
      "    45     0.624279   0.693663   0.551533                    \n",
      "    46     0.626332   0.696065   0.558572                    \n",
      "    47     0.612964   0.682795   0.579688                    \n",
      "    48     0.634012   0.68278    0.58371                     \n",
      "    49     0.630928   0.686954   0.571644                    \n",
      "    50     0.616392   0.697121   0.565611                    \n",
      "    51     0.595579   0.691744   0.567119                    \n",
      "    52     0.608113   0.722862   0.527401                    \n",
      "    53     0.623131   0.695922   0.556058                    \n",
      "    54     0.605296   0.696193   0.5455                      \n",
      "    55     0.612452   0.684666   0.569633                    \n",
      "    56     0.595357   0.693908   0.57265                     \n",
      "    57     0.604532   0.711353   0.535948                    \n",
      "    58     0.599901   0.687828   0.565611                    \n",
      "    59     0.613468   0.696491   0.570136                    \n",
      "    60     0.601652   0.688895   0.575666                    \n",
      "    61     0.608832   0.695406   0.570639                    \n",
      "    62     0.594483   0.706493   0.551031                    \n",
      "    63     0.597751   0.711135   0.533434                    \n",
      "    64     0.614674   0.699518   0.585721                    \n",
      "    65     0.613319   0.707548   0.553042                    \n",
      "    66     0.589074   0.703589   0.550528                    \n",
      "    67     0.589963   0.695861   0.567622                    \n",
      "    68     0.594049   0.698652   0.563097                    \n",
      "    69     0.595171   0.701899   0.584716                    \n",
      "    70     0.599164   0.702524   0.574158                    \n",
      "    71     0.594037   0.702678   0.591252                    \n",
      "    72     0.579126   0.722562   0.533434                    \n",
      "    73     0.563049   0.731622   0.524384                    \n",
      "    74     0.577778   0.707285   0.573655                    \n",
      "    75     0.595144   0.707658   0.577174                    \n",
      "    76     0.574733   0.70925    0.558069                    \n",
      "    77     0.572769   0.713954   0.580694                    \n",
      "    78     0.580658   0.7102     0.574661                    \n",
      "    79     0.578035   0.714274   0.541981                    \n",
      "    80     0.567725   0.732588   0.541981                    \n",
      "    81     0.566427   0.720791   0.5636                      \n",
      "    82     0.562333   0.717286   0.56008                     \n",
      "    83     0.5496     0.714821   0.565108                    \n",
      "    84     0.57463    0.704965   0.567622                    \n",
      "    85     0.559504   0.719052   0.573655                    \n",
      "    86     0.561202   0.711712   0.566616                    \n",
      "    87     0.565406   0.731315   0.538462                    \n",
      "    88     0.549251   0.714722   0.561086                    \n",
      "    89     0.562726   0.713664   0.574158                    \n",
      "    90     0.545996   0.718867   0.555556                    \n",
      "    91     0.546429   0.726194   0.554047                    \n",
      "    92     0.53827    0.717986   0.567119                    \n",
      "    93     0.552342   0.715912   0.57265                     \n",
      "    94     0.55488    0.726843   0.540975                    \n",
      "    95     0.545109   0.720876   0.564103                    \n",
      "    96     0.564138   0.733378   0.542986                    \n",
      "    97     0.566392   0.722782   0.580694                    \n",
      "    98     0.559928   0.741786   0.580694                    \n",
      "    99     0.551619   0.716831   0.558069                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7168308818322321, 0.5580693990396698]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.precompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec238a7c2b6489e9136459cb85d5ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.644201   0.702035   0.558069  \n",
      "    1      0.602646   0.693725   0.559578                    \n",
      "    2      0.611055   0.692102   0.570639                    \n",
      "    3      0.60558    0.689898   0.564103                    \n",
      "    4      0.602614   0.688689   0.564103                    \n",
      "    5      0.595946   0.686846   0.567119                    \n",
      "    6      0.599455   0.690465   0.561086                    \n",
      "    7      0.598676   0.692953   0.54902                     \n",
      "    8      0.608997   0.692893   0.559578                    \n",
      "    9      0.611142   0.690091   0.57265                     \n",
      "    10     0.606026   0.694665   0.561589                    \n",
      "    11     0.598044   0.695447   0.565611                    \n",
      "    12     0.605047   0.695386   0.563097                    \n",
      "    13     0.599862   0.691376   0.577677                    \n",
      "    14     0.599632   0.69501    0.566114                    \n",
      "    15     0.602015   0.695006   0.561086                    \n",
      "    16     0.597252   0.69751    0.555053                    \n",
      "    17     0.59716    0.695521   0.569633                    \n",
      "    18     0.607726   0.693869   0.565611                    \n",
      "    19     0.612859   0.694528   0.561589                    \n",
      "    20     0.600867   0.696972   0.561086                    \n",
      "    21     0.602478   0.697638   0.554047                    \n",
      "    22     0.595405   0.697129   0.565611                    \n",
      "    23     0.600758   0.703065   0.537959                    \n",
      "    24     0.601924   0.695156   0.568125                    \n",
      "    25     0.593306   0.695679   0.572147                    \n",
      "    26     0.603144   0.694348   0.569633                    \n",
      "    27     0.587398   0.694362   0.562092                    \n",
      "    28     0.596065   0.692214   0.56913                     \n",
      "    29     0.595872   0.691114   0.564103                    \n",
      "    30     0.594601   0.695102   0.558572                    \n",
      "    31     0.589212   0.690626   0.577174                    \n",
      "    32     0.582172   0.694986   0.562594                    \n",
      "    33     0.592491   0.696498   0.566616                    \n",
      "    34     0.584931   0.694561   0.564103                    \n",
      "    35     0.593414   0.695669   0.575666                    \n",
      "    36     0.566373   0.696083   0.566114                    \n",
      "    37     0.591815   0.696884   0.556058                    \n",
      "    38     0.581062   0.694679   0.562092                    \n",
      "    39     0.625403   0.688981   0.572147                    \n",
      "    40     0.593423   0.697281   0.55455                     \n",
      "    41     0.595514   0.688675   0.562594                    \n",
      "    42     0.597934   0.696221   0.562092                    \n",
      "    43     0.595597   0.696216   0.563097                    \n",
      "    44     0.576935   0.695474   0.562594                    \n",
      "    45     0.580853   0.693843   0.556561                    \n",
      "    46     0.582043   0.694318   0.562092                    \n",
      "    47     0.591629   0.692702   0.56913                     \n",
      "    48     0.595643   0.69452    0.5636                      \n",
      "    49     0.575693   0.70145    0.552539                    \n",
      "    50     0.585328   0.691101   0.562594                    \n",
      "    51     0.584184   0.695827   0.564605                    \n",
      "    52     0.57247    0.691156   0.569633                    \n",
      "    53     0.574074   0.693528   0.5636                      \n",
      "    54     0.579604   0.68894    0.579688                    \n",
      "    55     0.576838   0.69459    0.557064                    \n",
      "    56     0.580755   0.692977   0.553545                    \n",
      "    57     0.597372   0.692233   0.566616                    \n",
      "    58     0.590467   0.69792    0.555053                    \n",
      "    59     0.586977   0.697608   0.559578                    \n",
      "    60     0.594088   0.696589   0.563097                    \n",
      "    61     0.573412   0.698043   0.554047                    \n",
      "    62     0.587359   0.705858   0.556561                    \n",
      "    63     0.589118   0.703191   0.551031                    \n",
      "    64     0.578837   0.705962   0.5455                      \n",
      "    65     0.584158   0.705646   0.552539                    \n",
      "    66     0.559453   0.702162   0.561589                    \n",
      "    67     0.584375   0.706785   0.552036                    \n",
      "    68     0.586377   0.706136   0.552036                    \n",
      "    69     0.580805   0.702172   0.555053                    \n",
      "    70     0.572469   0.698077   0.55455                     \n",
      "    71     0.583909   0.704887   0.551533                    \n",
      "    72     0.587683   0.699374   0.556561                    \n",
      "    73     0.559472   0.701821   0.566616                    \n",
      "    74     0.574139   0.699282   0.562594                    \n",
      "    75     0.572208   0.706668   0.53997                     \n",
      "    76     0.5612     0.704322   0.56008                     \n",
      "    77     0.56889    0.701377   0.5636                      \n",
      "    78     0.573183   0.702977   0.558572                    \n",
      "    79     0.568833   0.701813   0.557567                    \n",
      "    80     0.57163    0.702425   0.561086                    \n",
      "    81     0.579635   0.698935   0.552036                    \n",
      "    82     0.576263   0.708824   0.543992                    \n",
      "    83     0.566875   0.709599   0.537456                    \n",
      "    84     0.584862   0.707007   0.549522                    \n",
      "    85     0.579263   0.704739   0.548014                    \n",
      "    86     0.576429   0.710549   0.547511                    \n",
      "    87     0.574137   0.704271   0.552036                    \n",
      "    88     0.580485   0.70656    0.562092                    \n",
      "    89     0.565493   0.712457   0.547511                    \n",
      "    90     0.591594   0.70607    0.548517                    \n",
      "    91     0.573246   0.706227   0.565611                    \n",
      "    92     0.565767   0.708343   0.558572                    \n",
      "    93     0.579699   0.711572   0.561086                    \n",
      "    94     0.556827   0.710016   0.554047                    \n",
      "    95     0.583051   0.707732   0.548014                    \n",
      "    96     0.563199   0.704924   0.556561                    \n",
      "    97     0.565504   0.709572   0.547009                    \n",
      "    98     0.585398   0.709088   0.562092                    \n",
      "    99     0.571328   0.71026    0.55455                     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7102603737944752, 0.5545500428788083]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 100, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e3ef0571374658b4765e0917c32cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Starting training on small images for a few epochs, then switching to bigger images, and continuing training is an amazingly effective way to avoid overfitting.\n",
    "\n",
    "# http://forums.fast.ai/t/planet-classification-challenge/7824/96\n",
    "# set_data doesn’t change the model at all. It just gives it new data to train with.\n",
    "learn.set_data(get_data(299, bs)) \n",
    "learn.freeze()\n",
    "\n",
    "#Source:   \n",
    "#    def set_data(self, data, precompute=False):\n",
    "#        super().set_data(data)\n",
    "#        if precompute:\n",
    "#            self.unfreeze()\n",
    "#            self.save_fc1()\n",
    "#            self.freeze()\n",
    "#            self.precompute = True\n",
    "#        else:\n",
    "#            self.freeze()\n",
    "#File:      ~/fastai/courses/dl1/fastai/conv_learner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 3, 299, 299]),\n",
       "                           ('output_shape', [-1, 64, 150, 150]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(9408))])),\n",
       "             ('BatchNorm2d-2',\n",
       "              OrderedDict([('input_shape', [-1, 64, 150, 150]),\n",
       "                           ('output_shape', [-1, 64, 150, 150]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(128))])),\n",
       "             ('ReLU-3',\n",
       "              OrderedDict([('input_shape', [-1, 64, 150, 150]),\n",
       "                           ('output_shape', [-1, 64, 150, 150]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('MaxPool2d-4',\n",
       "              OrderedDict([('input_shape', [-1, 64, 150, 150]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-5',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(36864))])),\n",
       "             ('BatchNorm2d-6',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(128))])),\n",
       "             ('ReLU-7',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-8',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(36864))])),\n",
       "             ('BatchNorm2d-9',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(128))])),\n",
       "             ('ReLU-10',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-11',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-12',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(36864))])),\n",
       "             ('BatchNorm2d-13',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(128))])),\n",
       "             ('ReLU-14',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-15',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(36864))])),\n",
       "             ('BatchNorm2d-16',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(128))])),\n",
       "             ('ReLU-17',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-18',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-19',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(36864))])),\n",
       "             ('BatchNorm2d-20',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(128))])),\n",
       "             ('ReLU-21',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-22',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(36864))])),\n",
       "             ('BatchNorm2d-23',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(128))])),\n",
       "             ('ReLU-24',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-25',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 64, 75, 75]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-26',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(73728))])),\n",
       "             ('BatchNorm2d-27',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-28',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-29',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(147456))])),\n",
       "             ('BatchNorm2d-30',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('Conv2d-31',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(8192))])),\n",
       "             ('BatchNorm2d-32',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-33',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-34',\n",
       "              OrderedDict([('input_shape', [-1, 64, 75, 75]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-35',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(147456))])),\n",
       "             ('BatchNorm2d-36',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-37',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-38',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(147456))])),\n",
       "             ('BatchNorm2d-39',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-40',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-41',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-42',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(147456))])),\n",
       "             ('BatchNorm2d-43',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-44',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-45',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(147456))])),\n",
       "             ('BatchNorm2d-46',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-47',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-48',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-49',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(147456))])),\n",
       "             ('BatchNorm2d-50',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-51',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-52',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(147456))])),\n",
       "             ('BatchNorm2d-53',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(256))])),\n",
       "             ('ReLU-54',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-55',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 128, 38, 38]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-56',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(294912))])),\n",
       "             ('BatchNorm2d-57',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-58',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-59',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-60',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('Conv2d-61',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(32768))])),\n",
       "             ('BatchNorm2d-62',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-63',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-64',\n",
       "              OrderedDict([('input_shape', [-1, 128, 38, 38]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-65',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-66',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-67',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-68',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-69',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-70',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-71',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-72',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-73',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-74',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-75',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-76',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-77',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-78',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-79',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-80',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-81',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-82',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-83',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-84',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-85',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-86',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-87',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-88',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-89',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-90',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-91',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-92',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-93',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-94',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-95',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-96',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(589824))])),\n",
       "             ('BatchNorm2d-97',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(512))])),\n",
       "             ('ReLU-98',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-99',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 256, 19, 19]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-100',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1179648))])),\n",
       "             ('BatchNorm2d-101',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('ReLU-102',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-103',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(2359296))])),\n",
       "             ('BatchNorm2d-104',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('Conv2d-105',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(131072))])),\n",
       "             ('BatchNorm2d-106',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('ReLU-107',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-108',\n",
       "              OrderedDict([('input_shape', [-1, 256, 19, 19]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-109',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(2359296))])),\n",
       "             ('BatchNorm2d-110',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('ReLU-111',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-112',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(2359296))])),\n",
       "             ('BatchNorm2d-113',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('ReLU-114',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-115',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-116',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(2359296))])),\n",
       "             ('BatchNorm2d-117',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('ReLU-118',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-119',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(2359296))])),\n",
       "             ('BatchNorm2d-120',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('trainable', False),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('ReLU-121',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BasicBlock-122',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 10, 10]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveMaxPool2d-123',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveAvgPool2d-124',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 512, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveConcatPool2d-125',\n",
       "              OrderedDict([('input_shape', [-1, 512, 10, 10]),\n",
       "                           ('output_shape', [-1, 1024, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Flatten-126',\n",
       "              OrderedDict([('input_shape', [-1, 1024, 1, 1]),\n",
       "                           ('output_shape', [-1, 1024]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm1d-127',\n",
       "              OrderedDict([('input_shape', [-1, 1024]),\n",
       "                           ('output_shape', [-1, 1024]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', tensor(2048))])),\n",
       "             ('Dropout-128',\n",
       "              OrderedDict([('input_shape', [-1, 1024]),\n",
       "                           ('output_shape', [-1, 1024]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-129',\n",
       "              OrderedDict([('input_shape', [-1, 1024]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', tensor(524800))])),\n",
       "             ('ReLU-130',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm1d-131',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', tensor(1024))])),\n",
       "             ('Dropout-132',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 512]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-133',\n",
       "              OrderedDict([('input_shape', [-1, 512]),\n",
       "                           ('output_shape', [-1, 2]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', tensor(1026))])),\n",
       "             ('LogSoftmax-134',\n",
       "              OrderedDict([('input_shape', [-1, 2]),\n",
       "                           ('output_shape', [-1, 2]),\n",
       "                           ('nb_params', 0)]))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c00b656e0f420a94732a929250ac1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.624505   0.708039   0.564605  \n",
      "    1      0.604895   0.698083   0.566616                    \n",
      "    2      0.58685    0.70948    0.544997                    \n",
      "    3      0.611657   0.70897    0.5455                      \n",
      "    4      0.605683   0.704298   0.559578                    \n",
      "    5      0.605451   0.700077   0.566114                    \n",
      "    6      0.608663   0.697308   0.574661                    \n",
      "    7      0.600216   0.70359    0.559578                    \n",
      "    8      0.601635   0.70107    0.556561                    \n",
      "    9      0.60093    0.699075   0.567622                    \n",
      "    10     0.589929   0.701714   0.567119                    \n",
      "    11     0.602794   0.697521   0.574158                    \n",
      "    12     0.595437   0.697394   0.570136                    \n",
      "    13     0.586751   0.702555   0.551533                    \n",
      "    14     0.600834   0.699458   0.565611                    \n",
      "    15     0.59538    0.700188   0.562092                    \n",
      "    16     0.605083   0.698744   0.555053                    \n",
      "    17     0.585917   0.704101   0.561086                    \n",
      "    18     0.590803   0.701289   0.559578                    \n",
      "    19     0.5969     0.705741   0.542484                    \n",
      "    20     0.58771    0.698029   0.573152                    \n",
      "    21     0.596534   0.701855   0.559075                    \n",
      "    22     0.592552   0.70413    0.54902                     \n",
      "    23     0.583482   0.705781   0.551031                    \n",
      "    24     0.593193   0.699674   0.575163                    \n",
      "    25     0.609967   0.705169   0.558572                    \n",
      "    26     0.608388   0.70295    0.567119                    \n",
      "    27     0.588397   0.706969   0.560583                    \n",
      "    28     0.597296   0.70636    0.558572                    \n",
      "    29     0.59061    0.711286   0.57265                     \n",
      "    30     0.582962   0.70945    0.550025                    \n",
      "    31     0.590474   0.711783   0.566616                    \n",
      "    32     0.5885     0.707933   0.565611                    \n",
      "    33     0.59753    0.709549   0.565108                    \n",
      "    34     0.594579   0.71284    0.562594                    \n",
      "    35     0.586839   0.70848    0.557064                    \n",
      "    36     0.581593   0.711022   0.555053                    \n",
      "    37     0.574704   0.708682   0.574661                    \n",
      "    38     0.585842   0.71147    0.539467                    \n",
      "    39     0.597321   0.711697   0.553042                    \n",
      "    40     0.602311   0.703549   0.574661                    \n",
      "    41     0.591293   0.709408   0.556058                    \n",
      "    42     0.577643   0.706786   0.557064                    \n",
      "    43     0.590831   0.705183   0.57265                     \n",
      "    44     0.57961    0.705895   0.560583                    \n",
      "    45     0.571598   0.707493   0.571644                    \n",
      "    46     0.582491   0.706548   0.567622                    \n",
      "    47     0.57176    0.705434   0.566114                    \n",
      "    48     0.592234   0.707464   0.567622                    \n",
      "    49     0.574883   0.706503   0.580694                    \n",
      "    50     0.603969   0.716161   0.538462                    \n",
      "    51     0.573201   0.710712   0.559075                    \n",
      "    52     0.576196   0.709991   0.562594                    \n",
      "    53     0.583405   0.711704   0.558572                    \n",
      "    54     0.566082   0.710023   0.570639                    \n",
      "    55     0.598344   0.716231   0.543992                    \n",
      "    56     0.564983   0.716892   0.572147                    \n",
      "    57     0.586694   0.718309   0.541981                    \n",
      "    58     0.57056    0.715265   0.558572                    \n",
      "    59     0.573408   0.717448   0.550528                    \n",
      "    60     0.575916   0.722451   0.542484                    \n",
      "    61     0.581572   0.711713   0.573655                    \n",
      "    62     0.566749   0.713773   0.580694                    \n",
      "    63     0.569771   0.712552   0.561086                    \n",
      "    64     0.586032   0.718212   0.551031                    \n",
      "    65     0.576827   0.717383   0.572147                    \n",
      "    66     0.571819   0.720027   0.551031                    \n",
      "    67     0.565857   0.719246   0.542484                    \n",
      "    68     0.582233   0.720443   0.566616                    \n",
      "    69     0.572259   0.722495   0.55455                     \n",
      "    70     0.57717    0.719733   0.562594                    \n",
      "    71     0.563957   0.724045   0.537456                    \n",
      "    72     0.574187   0.720786   0.56008                     \n",
      "    73     0.587678   0.719425   0.54902                     \n",
      "    74     0.587035   0.717032   0.543992                    \n",
      "    75     0.574548   0.711931   0.556058                    \n",
      "    76     0.582394   0.716257   0.558572                    \n",
      "    77     0.56123    0.718747   0.555556                    \n",
      "    78     0.570024   0.716725   0.554047                    \n",
      "    79     0.570576   0.713386   0.565108                    \n",
      "    80     0.591287   0.725087   0.543992                    \n",
      "    81     0.567695   0.713818   0.547009                    \n",
      "    82     0.570906   0.728555   0.526395                    \n",
      "    83     0.566586   0.717052   0.565108                    \n",
      "    84     0.562493   0.717734   0.546506                    \n",
      "    85     0.574901   0.715404   0.564605                    \n",
      "    86     0.555256   0.716424   0.561086                    \n",
      "    87     0.570249   0.716025   0.565108                    \n",
      "    88     0.551386   0.722179   0.548517                    \n",
      "    89     0.57323    0.724352   0.531423                    \n",
      "    90     0.571769   0.724807   0.538964                    \n",
      "    91     0.565292   0.730568   0.53645                     \n",
      "    92     0.559553   0.726115   0.551533                    \n",
      "    93     0.555754   0.721375   0.553545                    \n",
      "    94     0.561368   0.723024   0.548014                    \n",
      "    95     0.561166   0.725279   0.53997                     \n",
      "    96     0.578899   0.728585   0.568627                    \n",
      "    97     0.571559   0.717709   0.565108                    \n",
      "    98     0.564948   0.719247   0.558572                    \n",
      "    99     0.581427   0.717567   0.553545                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7175673862208428, 0.5535445105436161]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(1e-2, 100, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss is much lower than training loss. This is a sign of underfitting. Cycle_len=1 may be too short. Let's set cycle_mult=2 to find better parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "# set requires_grads to be True for all layers, so they can be updated\n",
    "\n",
    "learning_rate = [1e-5, 1e-5, 1e-4]\n",
    "# learning rate is set so that deepest third of layers have a rate of 0.001, # middle layers have a rate of 0.01, and final layers 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32582d0af35f45e1bc3c37309d1c44fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 166/332 [00:48<00:49,  3.34it/s, loss=0.73] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8622b6638828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# When you are under fitting, it means cycle_len=1 is too short (learning rate is getting reset before it had the chance to zoom in properly).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1+2+4 = 7 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \"\"\"\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# When you are under fitting, it means cycle_len=1 is too short (learning rate is getting reset before it had the chance to zoom in properly).\n",
    "learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2) # 1+2+4 = 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loss and validation loss are getting closer and smaller. We are on right track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA() # (5, 2044, 120), (2044,)\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(probs, y), metrics.log_loss(y, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.val_ds.y), data.val_ds.y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 13\n",
    "print(data.val_ds.y[num])\n",
    "print(np.argmax(probs[num]))\n",
    "\n",
    "print(probs[num])\n",
    "data.val_ds.fnames[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(probs,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame([data.val_ds.y,np.argmax(probs,axis = 1),\n",
    "                            [each[1] for each in np.argsort(-probs,axis = 1)],\n",
    "                            data.val_ds.fnames]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.loc[:,'acc1'] = predictions[0] == predictions[1]\n",
    "predictions.loc[:,'acc2'] = predictions[0] == predictions[2]\n",
    "((predictions.acc1) | (predictions.acc2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.acc1.sum()/1883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('299_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('299_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 50, cycle_len=2) # 1+1 = 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('299_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(probs, y), metrics.log_loss(y, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is so similar to ImageNet dataset. Training convolution layers doesn't help much. We are not going to unfreeze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create submission\n",
    "\n",
    "https://youtu.be/9C06ZPF8Uuc?t=1905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_ds.fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA(is_test=True) # use test dataset rather than validation dataset\n",
    "probs = np.mean(np.exp(log_preds),0)\n",
    "#accuracy_np(probs, y), metrcs.log_loss(y, probs) # This does not make sense since test dataset has no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape # (n_images, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(probs)\n",
    "df.columns = data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'id', [o[5:-4] for o in data.test_ds.fnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM = f'{PATH}/subm/'\n",
    "os.makedirs(SUBM, exist_ok=True)\n",
    "df.to_csv(f'{SUBM}subm.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(f'{SUBM}subm.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = data.val_ds.fnames[0]\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(PATH + fn).resize((150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1.\n",
    "trn_tfms, val_tfms = tfms_from_model(arch, sz)\n",
    "ds = FilesIndexArrayDataset([fn], np.array([0]), val_tfms, PATH)\n",
    "dl = DataLoader(ds)\n",
    "preds = learn.predict_dl(dl)\n",
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.classes[np.argmax(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2.\n",
    "trn_tfms, val_tfms = tfms_from_model(arch, sz)\n",
    "im = val_tfms(open_image(PATH + fn)) # open_image() returns numpy.ndarray\n",
    "preds = learn.predict_array(im[None])\n",
    "np.argmax(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
